{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, to futher explore our predictive model's abilities, we took additional pre-labeled disaster twitter datasets and ran predictions based on the unseen twitter data.  found a dataset from CrisisLEX that contained labeled tweets from a 2015 Earthquake from Nepal as well as flood in Queensland. These datasets were used solely to test the model we trained ability to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in dataset focusing on the earthquake.\n",
    "testing_df = pd.read_csv('2015_Nepal_Earthquake_train.tsv', sep='\\t', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>591902739002560512</td>\n",
       "      <td>RT @AnupKaphle: #Nepal's prime minister addres...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>592939706788216832</td>\n",
       "      <td>@jonsnowC4 So have we; read our friends blog f...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>592591542168252416</td>\n",
       "      <td>Lend a helping hand if you can #Nepal https://...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>591903009279385600</td>\n",
       "      <td>@shilpaanand they've managed to reach Kathmand...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>592099765271199744</td>\n",
       "      <td>Israel Sending Aid Teams to Nepal After Quake:...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  591902739002560512  RT @AnupKaphle: #Nepal's prime minister addres...   \n",
       "1  592939706788216832  @jonsnowC4 So have we; read our friends blog f...   \n",
       "2  592591542168252416  Lend a helping hand if you can #Nepal https://...   \n",
       "3  591903009279385600  @shilpaanand they've managed to reach Kathmand...   \n",
       "4  592099765271199744  Israel Sending Aid Teams to Nepal After Quake:...   \n",
       "\n",
       "      label  \n",
       "0  relevant  \n",
       "1  relevant  \n",
       "2  relevant  \n",
       "3  relevant  \n",
       "4  relevant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_relevant    3606\n",
       "relevant        3293\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "text        0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapped predicted \"label\" column to 1's and 0's for ease of reading\n",
    "\n",
    "testing_df['label'] = testing_df['label'].map({'not_relevant':0, 'relevant': 1,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_relevant    0.522684\n",
       "relevant        0.477316\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline score\n",
    "\n",
    "testing_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded in the ultimate choice saved voting classifier model.\n",
    "\n",
    "with open('vote_model_save2', 'rb') as f:\n",
    "    trained_model3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used regex to clean the data set of any html and other extraneious symbols\n",
    "\n",
    "testing_df['text'] = testing_df['text'].map(lambda x: x.lower())\n",
    "testing_df['text'] = testing_df['text'].map(lambda x: re.sub('\\s[\\/]?r\\/[^s]+', ' ', x))\n",
    "testing_df['text'] = testing_df['text'].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))\n",
    "testing_df['text'] = testing_df['text'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df['predictions'] = trained_model3.predict(testing_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df['sum'] = testing_df['label'] + testing_df['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created a 'sum' colum in order to compare the 'label' column to the predicted column. In doing this:\n",
    "- \"2\" would mean the tweet had previously been marked as being relevant to the disaster and the model **correctly** predicted it was relevant.\n",
    "- \"1\" would mean the tweet had been previously marked not relevant and the model predicted it to be relvant, therefore an **incorrect** prediction\n",
    "- \"0\" would mean the tweet had been previously marked not relevant and the model **correctly** predicted it to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.389332\n",
       "0    0.313959\n",
       "2    0.296710\n",
       "Name: sum, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df['sum'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the model scored 69% accuracy on this earthquake dataset. Not great, but still above the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the first flood dataset\n",
    "\n",
    "flood_test_df = pd.read_csv('2013_Queensland_Floods_dev.tsv', sep='\\t', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>295530424854269952</td>\n",
       "      <td>Fuck It.. Chelsea should have been all over Br...</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>297305363668140032</td>\n",
       "      <td>Hey Dana Does @Alistairovereem gets the title ...</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>296215855602204672</td>\n",
       "      <td>@mimstacey @janecaro game over. In most states...</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>297199390697852928</td>\n",
       "      <td>I just made a new word: Awkwul . A mix between...</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>295358655036010497</td>\n",
       "      <td>Nothing like stifling heat to make me want to ...</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>296115486503075840</td>\n",
       "      <td>Grafton Queensland Flood Peaks at 10.7 Meters:...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>295937544577748993</td>\n",
       "      <td>Helicopters Deployed to Rescue Flood Victims i...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>296180025714155520</td>\n",
       "      <td>RT @maltesemanor: NO! we've suffered enough! M...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>296223927305383937</td>\n",
       "      <td>@skeletonunicorn the waters upto the door, my ...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>295757308875636736</td>\n",
       "      <td>Queensland's flood crisis deepens as death tol...</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0     295530424854269952  Fuck It.. Chelsea should have been all over Br...   \n",
       "1     297305363668140032  Hey Dana Does @Alistairovereem gets the title ...   \n",
       "2     296215855602204672  @mimstacey @janecaro game over. In most states...   \n",
       "3     297199390697852928  I just made a new word: Awkwul . A mix between...   \n",
       "4     295358655036010497  Nothing like stifling heat to make me want to ...   \n",
       "...                  ...                                                ...   \n",
       "998   296115486503075840  Grafton Queensland Flood Peaks at 10.7 Meters:...   \n",
       "999   295937544577748993  Helicopters Deployed to Rescue Flood Victims i...   \n",
       "1000  296180025714155520  RT @maltesemanor: NO! we've suffered enough! M...   \n",
       "1001  296223927305383937  @skeletonunicorn the waters upto the door, my ...   \n",
       "1002  295757308875636736  Queensland's flood crisis deepens as death tol...   \n",
       "\n",
       "             label  \n",
       "0     not_relevant  \n",
       "1     not_relevant  \n",
       "2     not_relevant  \n",
       "3     not_relevant  \n",
       "4     not_relevant  \n",
       "...            ...  \n",
       "998       relevant  \n",
       "999       relevant  \n",
       "1000      relevant  \n",
       "1001      relevant  \n",
       "1002      relevant  \n",
       "\n",
       "[1003 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flood_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.539382\n",
       "0    0.460618\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline score\n",
    "\n",
    "flood_test_df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapped \"label\" column to 1's and 0's for ease of reading\n",
    "\n",
    "flood_test_df['label'] = flood_test_df['label'].map({'not_relevant':0, 'relevant': 1,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used regex to clean the data set of any html and other extraneious symbols\n",
    "\n",
    "flood_test_df['text'] = flood_test_df['text'].map(lambda x: x.lower())\n",
    "flood_test_df['text'] = flood_test_df['text'].map(lambda x: re.sub('\\s[\\/]?r\\/[^s]+', ' ', x))\n",
    "flood_test_df['text'] = flood_test_df['text'].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))\n",
    "flood_test_df['text'] = flood_test_df['text'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predictions\n",
    "\n",
    "flood_test_df['predictions'] = trained_model3.predict(flood_test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>295530424854269952</td>\n",
       "      <td>fuck it.. chelsea should have been all over br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>297305363668140032</td>\n",
       "      <td>hey dana does @alistairovereem gets the title ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>296215855602204672</td>\n",
       "      <td>@mimstacey @janecaro game over. in most states...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>297199390697852928</td>\n",
       "      <td>i just made a new word: awkwul . a mix between...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>295358655036010497</td>\n",
       "      <td>nothing like stifling heat to make me want to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>296115486503075840</td>\n",
       "      <td>grafton queensland flood peaks at 10.7 meters:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>295937544577748993</td>\n",
       "      <td>helicopters deployed to rescue flood victims i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>296180025714155520</td>\n",
       "      <td>rt @maltesemanor: no weve suffered enough mt @...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>296223927305383937</td>\n",
       "      <td>@skeletonunicorn the waters upto the door, my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>295757308875636736</td>\n",
       "      <td>queenslands flood crisis deepens as death toll...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0     295530424854269952  fuck it.. chelsea should have been all over br...   \n",
       "1     297305363668140032  hey dana does @alistairovereem gets the title ...   \n",
       "2     296215855602204672  @mimstacey @janecaro game over. in most states...   \n",
       "3     297199390697852928  i just made a new word: awkwul . a mix between...   \n",
       "4     295358655036010497  nothing like stifling heat to make me want to ...   \n",
       "...                  ...                                                ...   \n",
       "998   296115486503075840  grafton queensland flood peaks at 10.7 meters:...   \n",
       "999   295937544577748993  helicopters deployed to rescue flood victims i...   \n",
       "1000  296180025714155520  rt @maltesemanor: no weve suffered enough mt @...   \n",
       "1001  296223927305383937  @skeletonunicorn the waters upto the door, my ...   \n",
       "1002  295757308875636736  queenslands flood crisis deepens as death toll...   \n",
       "\n",
       "      label  predictions  \n",
       "0         0            0  \n",
       "1         0            0  \n",
       "2         0            0  \n",
       "3         0            0  \n",
       "4         0            0  \n",
       "...     ...          ...  \n",
       "998       1            1  \n",
       "999       1            1  \n",
       "1000      1            1  \n",
       "1001      1            0  \n",
       "1002      1            1  \n",
       "\n",
       "[1003 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flood_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created a 'sum' colum in order to compare the 'label' column to the predicted column. In doing this:\n",
    "- \"2\" would mean the tweet had previously been marked as being relevant to the disaster and the model **correctly** predicted it was relevant.\n",
    "- \"1\" would mean the tweet had been previously marked not relevant and the model predicted it to be relvant, therefore an **incorrect** prediction\n",
    "- \"0\" would mean the tweet had been previously marked not relevant and the model **correctly** predicted it to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_test_df['sum'] = flood_test_df['label'] + flood_test_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.440678\n",
       "0    0.433699\n",
       "1    0.125623\n",
       "Name: sum, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores for the predicted test.`\n",
    "flood_test_df['sum'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see above that the model was 89% correct when it came to predicting if the tweet was relevant or not for this flood dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a different flood dataset to test on.\n",
    "\n",
    "flood_test_df_2 = pd.read_csv('2013_Queensland_Floods_train.tsv', sep='\\t', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant        0.539625\n",
       "not_relevant    0.460375\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flood_test_df_2['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_test_df_2['label'] = flood_test_df_2['label'].map({'not_relevant':0, 'relevant': 1,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used regex to clean the data set of any html and other extraneious symbols\n",
    "\n",
    "flood_test_df_2['text'] = flood_test_df_2['text'].map(lambda x: x.lower())\n",
    "flood_test_df_2['text'] = flood_test_df_2['text'].map(lambda x: re.sub('\\s[\\/]?r\\/[^s]+', ' ', x))\n",
    "flood_test_df_2['text'] = flood_test_df_2['text'].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x))\n",
    "flood_test_df_2['text'] = flood_test_df_2['text'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_test_df_2['predictions'] = trained_model3.predict(flood_test_df_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_test_df_2['sum'] = flood_test_df_2['label'] + flood_test_df_2['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.462701\n",
       "0    0.434790\n",
       "1    0.102509\n",
       "Name: sum, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flood_test_df_2['sum'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar to above, the scoring shows that this testing dataset was 89% accurate from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
